{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1ab0be",
   "metadata": {},
   "source": [
    "# 1. Import Spark Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec7f7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/spark-3.2.0-bin-hadoop3.2\")\n",
    "from IPython.display import display, clear_output\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.streaming import DataStreamReader\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import html\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 250\n",
    "pd.options.display.max_colwidth = 150\n",
    "sns.set(color_codes=True)\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c73e2b",
   "metadata": {},
   "source": [
    "# 2. Build SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e3752ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    ".master(\"local[*]\") \\\n",
    ".appName(\"ml\") \\\n",
    ".config(\"spark.memory.fraction\",\"0.8\") \\\n",
    ".config(\"spark.executor.memory\",\"8g\") \\\n",
    ".config(\"spark.driver.memory\",\"8g\") \\\n",
    ".config(\"spark.sql.hive.filesourcePartitionFileCacheSize\", \"621440000\") \\\n",
    ".config(\"spark.sql.sources.bucketing.maxBuckets\", \"100000\") \\\n",
    ".config(\"spark.sql.shuffle.partitions\", \"2000\") \\\n",
    ".config(\"spark.driver.maxResultSize\",\"2g\") \\\n",
    ".config(\"spark.shuffle.file.buffer\",\"64k\") \\\n",
    ".config(\"spark.scheduler.listenerbus.eventqueue.capacity\", \"1000\") \\\n",
    ".config(\"spark.broadcast.blockSize\", \"8m\") \\\n",
    ".config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    ".config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0')\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e3c60",
   "metadata": {},
   "source": [
    "# 3. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c645fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/20 17:16:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/12/20 17:16:55 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "21/12/20 17:16:55 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/home/jovyan/work/lr_model/lr_sakarya_twitter_sentiment_analysis_model.pkl\"\n",
    "sentiment_model = PipelineModel.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cd92c",
   "metadata": {},
   "source": [
    "# 4. Build Spark Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52778a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stream = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"159.223.22.116:9092\") \\\n",
    "  .option(\"subscribe\", \"tweet\") \\\n",
    "  .option(\"startingOffsets\", \"latest\") \\\n",
    "  .option(\"kafka.request.timeout.ms\", \"60000\") \\\n",
    "  .option(\"kafka.session.timeout.ms\", \"30000\") \\\n",
    "  .option(\"kafkaConsumer.pollTimeoutMs\", \"5120\") \\\n",
    "  .option(\"failOnDataLoss\", \"true\") \\\n",
    "  .option(\"fetchOffset.numRetries\", \"5\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3003422",
   "metadata": {},
   "source": [
    "# 5. Convert Data Coming from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = StructType() \\\n",
    "        .add(\"createdAt\", IntegerType()) \\\n",
    "        .add(\"name\", StringType()) \\\n",
    "        .add(\"likeCount\", IntegerType()) \\\n",
    "        .add(\"quoteCount\", IntegerType()) \\\n",
    "        .add(\"replyCount\", IntegerType()) \\\n",
    "        .add(\"retweetCount\", IntegerType()) \\\n",
    "        .add(\"text\", StringType())\n",
    "\n",
    "df_stream_cast = df_stream.selectExpr(\"CAST(value AS STRING)\").select(from_json(col(\"value\"), df_schema).alias(\"values\"))\n",
    "df = df_stream_cast.select(\"values.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe92ac6",
   "metadata": {},
   "source": [
    "# 6. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "30449942",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def html_unescape(s: str):\n",
    "    if isinstance(s, str):\n",
    "        return html.unescape(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def clean_data(df: DataFrame):\n",
    "    url_regex = r\"((https?|ftp|file):\\/{2,3})+([-\\w+&@#/%=~|$?!:,.]*)|(www.)+([-\\w+&@#/%=~|$?!:,.]*)\"\n",
    "    email_regex = r\"[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{1,}\"\n",
    "    user_regex = r\"(@\\w{1,15})\"\n",
    "    \n",
    "    return (\n",
    "        df\n",
    "        \n",
    "        .withColumn(\"original_text\", f.col(\"text\"))\n",
    "        \n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), url_regex, \"\"))\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), email_regex, \"\"))\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), user_regex, \"\"))\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"#\", \" \"))\n",
    "        \n",
    "        .withColumn(\"text\", html_unescape(f.col(\"text\")))\n",
    "        \n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"[^a-zA-Z']\", \" \"))\n",
    "        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \" +\", \" \"))\n",
    "        .withColumn(\"text\", f.trim(f.col(\"text\")))\n",
    "        \n",
    "    \n",
    "        .filter(f.col(\"text\") != \"\").na.drop(subset=\"text\")\n",
    "    )\n",
    "\n",
    "df_clean=clean_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6615d3",
   "metadata": {},
   "source": [
    "# 7. Predict Sentiment Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0075d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentiment = sentiment_model.transform(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4702e0",
   "metadata": {},
   "source": [
    "# 8. Real Time Predicted Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3312f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = raw_sentiment.select(\n",
    "    \"createdAt\", \"name\", \"likeCount\",\"quoteCount\",\"replyCount\",\n",
    "    \"retweetCount\",\"text\", \"original_text\",\n",
    "    f.col(\"prediction\").alias(\"user_sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e398d70",
   "metadata": {},
   "source": [
    "# 9. Stream Aggregation Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06532120",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentiment_count = (\n",
    "    sentiment.filter(\"user_sentiment == 0\")\n",
    "    .select(f.col(\"user_sentiment\").alias(\"negative_sentiment\"))\n",
    "    .agg(f.count(\"negative_sentiment\"))\n",
    ")\n",
    "\n",
    "positive_sentiment_count = (\n",
    "    sentiment.filter(\"user_sentiment == 1\")\n",
    "    .select(f.col(\"user_sentiment\").alias(\"positive_sentiment\"))\n",
    "    .agg(f.count(\"positive_sentiment\"))\n",
    ")\n",
    "\n",
    "average_sentiment = sentiment.agg(f.avg(\"user_sentiment\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6c106",
   "metadata": {},
   "source": [
    "# 10. Real Time Predicted Data to Sink Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_writer = (\n",
    "    sentiment\n",
    "    .selectExpr(\"to_json(struct(*)) AS value\")\n",
    "    .writeStream\n",
    "    .queryName(\"emotion_sentiment\")\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"159.223.22.116:9092\")\n",
    "    .option(\"topic\", \"sentiment_topic\")\n",
    "    .option(\"checkpointLocation\", \"/home/jovyan/work/logs\")\n",
    ")\n",
    "\n",
    "query = stream_writer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d6fb8",
   "metadata": {},
   "source": [
    "# 11. Query Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b296684b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emotion_sentiment'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(query.lastProgress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476810a",
   "metadata": {},
   "source": [
    "# 12. For Blocking Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.streams.awaitAnyTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9808dd4",
   "metadata": {},
   "source": [
    "# 13. Stop Stream Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47627cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d4793",
   "metadata": {},
   "source": [
    "# 14. Stop SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
